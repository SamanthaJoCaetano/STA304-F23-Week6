---
title: "Multilevel Models"
author: "Emily Somerset"
subtitle: "STA304 - Lecture 6"
date: "Insert Date Here"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
library(lme4)
library(dplyr)
library(brms)
library(haven)
library(ggplot2)
library(dplyr)

### Load in the data
school <- read_dta("https://stats.idre.ucla.edu/stat/examples/imm/imm10.dta")

### Select a subset of the data
df1 <- school %>% 
  dplyr::select(schid, stuid, homework,public,math)
```

Show how the intercept of a model may vary by school. 
```{r, echo = FALSE}
ggplot(df1 %>% dplyr::filter(homework ==0), 
       aes(factor(schid), math))+
  geom_boxplot()+ 
  xlab("School ID")+ 
  scale_y_continuous(name = "Math Score", breaks = scales::pretty_breaks(n=10))+
  theme_bw()
```

## Model 1 

$$\begin{aligned}
\text{score}_{ij} &= \beta_0 + \beta_1 \text{Homework}_{ij} + \epsilon_{ij}\\
\epsilon_{ij} &\sim \text{Normal}(0,\sigma_\epsilon^2)
\end{aligned}$$

```{r}
mdl1 <- lm(math ~ homework, data = df1)
mdl1
```

## Model 2

$$\begin{aligned}
\text{score}_{ij} &= \beta_{0j} + \beta_1 \text{Homework}_{ij} + \epsilon_{ij}\\
\epsilon_{ij} &\sim \text{Normal}(0,\sigma_\epsilon^2)
\end{aligned}$$

```{r}
mdl2 <- lm(math ~ homework + factor(schid)-1, data = df1)
mdl2
```

## Model 3

$$\begin{aligned}
\text{score}_{ij} &= \beta_{0j} + \beta_1 \text{Homework}_{ij} + \epsilon_{ij}\\
\beta_{0j} &\sim \text{Normal}(\mu_{\beta_0},\sigma_{\beta_0}^2)\\
\epsilon_{ij} &\sim \text{Normal}(0,\sigma_\epsilon^2)
\end{aligned}$$

```{r}
mdl3 <- lmer(math ~ homework + (1|schid), data = df1)
mdl3
```

Extract the estimated coefficients from the model. Notice how the intercept varies by school but the coefficient for homework does not. 

```{r}
coef(mdl3)
```

Get the fitted values for our data. 

```{r}
predict(mdl3, newdata = df1)[1:4]

#or 

fitted(mdl3)[1:4]
```

Get the predicted values for a sample not in our data. 

```{r}

newdf = data.frame(homework = c(1,2,3,4,5))

X_design <- model.matrix(~homework, data = newdf)

X_design %*% summary(mdl3)$coef[,1] 
```

## Model 4

Fit a regression line for math versus homework for every school. 
```{r}
ggplot(df1, 
       aes(homework, math, col = factor(schid)))+
  geom_point()+ 
  geom_smooth(method = "lm", formula = y~x, se=FALSE)+
  scale_x_continuous(name = "Homework", breaks = scales::pretty_breaks(n=10))+
  scale_y_continuous(name = "Math Score", breaks = scales::pretty_breaks(n=10))+
  theme_bw()+ 
  labs(col = "School ID")
```

$$\begin{aligned}
\text{score}_{ij} &= \beta_{0j} + \beta_{1j} \text{Homework}_{ij} + \epsilon_{ij}\\
\beta_{0j} &\sim \text{Normal}(\mu_{\beta_0},\sigma_{\beta_0}^2)\\
\beta_{1j} &\sim \text{Normal}(\mu_{\beta_1},\sigma_{\beta_1}^2)\\
\epsilon_{ij} &\sim \text{Normal}(0,\sigma_\epsilon^2)
\end{aligned}$$

```{r}
mdl4 <- lmer(math ~ homework + (homework|schid), data = df1)
mdl4
```

Extract the estimated coefficients from the model. Notice how the intercept and coefficient for homework varies by school. 

```{r}
coef(mdl4)
```

Get the fitted values for our data. 

```{r}
predict(mdl4, newdata = df1)[1:4]

#or 

fitted(mdl4)[1:4]
```

Get the predicted values for a sample not in our data. 

```{r}

newdf = data.frame(homework = c(1,2,3,4,5))

X_design <- model.matrix(~homework, data = newdf)

X_design %*% summary(mdl4)$coef[,1] 
```




